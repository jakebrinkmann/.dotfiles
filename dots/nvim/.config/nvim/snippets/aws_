# SAM(Serverless Application Model)
poetry export -f requirements.txt --without-hashes > requirements.txt
sam init --location https://github.com/aws-samples/cookiecutter-aws-sam-python
sam build --use-container
sam package --output-template-file packaged.yaml --s3-bucket $BUCKET
sam deploy --stack-name $STACK --tags StackName=$STACK --capabilities CAPABILITY_IAM --no-fail-on-empty-changeset --s3-bucket $BUCKET --confirm-changeset
sam logs --stack-name $STACK --name $FUNCTION --tail
python serverless-application-model/bin/sam-translate.py --template-file=packaged.yaml --output-template=cft.json

# cdk
npx cdk init sample-app --language=typescript
npx cdk ls
npx cdk bootstrap \
  --profile ProjectXProd \
  --cloudformation-execution-policies 'arn:aws:iam::aws:policy/AdministratorAccess' \
  123456789012/us-east-1 123456789012/us-west-1

# aws.compute.EC2 (Elastic Compute Cloud)
aws ssm get-parameters-by-path \
  --path /aws/service/ami-amazon-linux-latest \
  --query "Parameters[].Name"
aws ssm get-parameters \
  --names /aws/service/ami-amazon-linux-latest/amzn2-ami-hvm-arm64-gp2 \
  --query 'Parameters[0].[Value]'
aws ec2 describe-images \
  --image-id $IMAGEID --query "Images[*].BlockDeviceMappings"
aws ec2 describe-images \
    --filters "Name=block-device-mapping.encrypted,Values=true" \
    --query 'Images[*].[ImageId]' \
    --output text
aws ec2 modify-instance-metadata-options \
    --instance-id i-INSTANCE-ID \
    --http-tokens required \ >> this sets the instance metadata to imdsv2, be careful!
    --http-put-response-hop-limit 3 \
    --http-endpoint enabled

# aws.compute.ECR (Elastic Container Registry)

# aws.compute.ECS (Elastic Container Service)
aws ecs list-clusters | jq '.clusterArns[]'
aws ecs list-tasks --cluster $CLUSTER | jq '.taskArns[]'
aws ecs describe-tasks --cluster $CLUSTER --tasks $TASK | jq '.tasks[].containers[].name'
aws ecs execute-command --cluster $CLUSTER \
    --task $TASK \
    --container $CONTAINER \
    --interactive \
    --command "/bin/sh"

# aws.compute.Lambda
aws lambda list-functions --query "Functions[?FunctionName | contains(@, 'LogSubmit')].FunctionName" --output text
aws lambda list-functions | jq ".Functions | group_by(.Runtime)|[.[]|{ (.[0].Runtime): [.[]|{ name: .FunctionName, timeout: .Timeout, memory: .MemorySize }] }]"
aws lambda list-functions | jq -r '[.Functions[]|{name: .FunctionName, env: .Environment.Variables}]|.[]|select(.env|length > 0)'
FILENAME=$(mktemp --suffix '.zip'); rm $FILENAME
pip install -r requirements.txt --target . && zip -r $FILENAME ./*
aws lambda update-function-code --function-name $LAMBDA --zip-file "fileb://$FILENAME" --publish | jq -r .LastUpdateStatus
aws lambda update-function-configuration --function-name $LAMBDA --timeout 30 --memory-size 256 | jq -r .LastUpdateStatus
aws lambda update-function-configuration --function-name $LAMBDA --handler "app.lambda_handler" --layers "arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPython:4" --environment "Variables={DB_SECRET_NAME=cca/database/site_api_read_write,DB_PROXY_ENDPOINT=cca-database-proxy.proxy-cx6atckrdwx5.us-east-1.rds.amazonaws.com}" | jq -r .LastUpdateStatus
aws lambda invoke  --function-name $LAMBDA --invocation-type RequestResponse --log-type Tail --payload "$(echo $EVENT | base64)" $tmpfile | jq -r .LogResult | base64 --decode

# aws.configure
aws configservice get-discovered-resource-counts --query "totalDiscoveredResources"

# aws.database.RDS (Relational Data Service)
aws rds describe-db-engine-versions --engine aurora-postgresql --query '*[].[EngineVersion]'
aws rds describe-engine-default-parameters --db-parameter-group-family mariadb10.6 \
   --query 'EngineDefaults.Parameters[?IsModifiable==`true`]'
aws rds describe-db-cluster-parameters --db-cluster-parameter-group-name default.aurora-postgresql14
aws rds describe-db-clusters | jq -r '.DBClusters[].DBClusterArn'
aws rds-data execute-statement \
  --resource-arn $DB_ARN \
  --secret-arn $SECRET_ARN \
  --database $DB_NAME \
  --sql "select * from "

# aws.database.DDB (DynamoDB NoSQL Database)
aws dynamodb list-tables  --query 'TableNames[]'
aws dynamodb scan --table-name $TABLE --max-items 1 --query 'Items[] | [0]'
aws dynamodb put-item \
    --table-name $TABLE \
    --item '{"Artist": {"S": "No One You Know"}}' \
    --return-values ALL_OLD
aws dynamodb get-item --table-name $TABLE --key '{"id": {"N": "'$KEY'"}}'
aws dynamodb delete-item --table-name $TABLE --key '{"id": {"S": "'$KEY'"}}'
aws dynamodb scan \
  --table-name Tables-YJX \
  --projection-expression "THING"
  --expression-attribute-names '{"#l1": "level1", "#l2": "level2"}' \
  --filter-expression '#l1.#l2 = :p' \
  --expression-attribute-values '{":p": {"S": "match"}}' \
  | jq '.Items[].THING.S'

# aws.engagement.SES (Simple Email Service)
aws ses verify-email-identity --email-address $jbrinkmann@sonifi.com
aws route53 list-hosted-zones-by-name --dns-name $HOSTEDZONENAME | jq -r .HostedZones[0].Id
aws ses verify-domain-identity --domain $HOSTEDZONENAME | jq -r .VerificationToken
aws ses list-identities --query 'Identities'
aws ses get-identity-verification-attributes --identities $jbrinkmann@sonifi.com
aws ses set-identity-mail-from-domain --identity $HOSTEDZONENAME --mail-from-domain "no-reply.$HOSTEDZONENAME" --behavior-on-mx-failure UseDefaultValue
aws sesv2 create-configuration-set-event-destination \
  --configuration-set-name EmailEventConfigSet \
  --event-destination-name EmailSnsEventDestination \
  --event-destination $(cat << '__JSON__' | jq -c
{
  "Enabled": true,
  "MatchingEventTypes": [
    "REJECT",
    "BOUNCE",
    "DELIVERY",
    "RENDERING_FAILURE"
  ],
  "SnsDestination": {
    "TopicArn": "$EmailEventTopicArn"
  }
}
__JSON__
cat << __JSON__ > $TMPFILE
{
  "Changes": [
    {
      "Action": "UPSERT",
      "ResourceRecordSet": {
        "Name": "_amazonses.$HOSTEDZONENAME",
        "Type": "TXT",
        "TTL": 1800,
        "ResourceRecords": [
          {
            "Value": "\"$TXTTOKEN\""
          }
        ]
      }
    },
    {
      "Action": "UPSERT",
      "ResourceRecordSet": {
        "Name": "no-reply.$HOSTEDZONENAME",
        "Type": "MX",
        "TTL": 300,
        "ResourceRecords": [
          {
            "Value": "10 feedback-smtp.us-east-1.amazonses.com"
          }
        ]
      }
    },
    {
      "Action": "UPSERT",
      "ResourceRecordSet": {
        "Name": "$HOSTEDZONENAME",
        "Type": "TXT",
        "TTL": 300,
        "ResourceRecords": [
          {
            "Value": "\"v=spf1 include:amazonses.com ~all\""
          }
        ]
      }
    }
  ]
}
__JSON__
aws route53 change-resource-record-sets --hosted-zone-id $HOSTEDZONEID --change-batch file://$TMPFILE

# aws.integration.SF (StepFunctions)
aws events list-event-buses --query 'EventBuses[].Name'
aws events put-events --entries "$EVENT"
aws stepfunctions list-state-machines --query 'stateMachines[].stateMachineArn'
aws stepfunctions start-execution --state-machine-arn $STATEMACHINE --input $EVENT

# aws.integration.SQS (Simple Queue Service)
aws sqs list-queues | jq -c '.QueueUrls[]'
aws sqs send-message --queue-url $QUEUE_URL --message-body file://$EVENT_PATH
aws sqs purge-queue --queue-url $(aws sqs get-queue-url --queue-name $QUEUE_NAME) && sleep 60
aws sqs get-queue-attributes --queue-url $QUEUE_URL --attribute-names All | jq -r .Attributes.ApproximateNumberOfMessages

# aws.integration.SNS (Simple Notification Service)
aws sns list-topics | jq -c '.Topics[].TopicArn'
aws sns list-topics --output table --query 'Topics[]'
aws sns list-topics --query "Topics[?contains(TopicArn, 'c')].TopicArn"
aws sns subscribe --topic-arn <value> --protocol email --notification-endpoint <email>
aws sns list-subscriptions | jq -c '.Subscriptions[] | select(.Protocol | test("email"))'
aws sns unsubscribe --subscription-arn <value>

# aws.management.CFN (CloudFormation Infrastructure Stack)
aws cloudformation list-exports | jq -c '.Exports[].Name'
aws cloudformation describe-stacks | jq -c '.Stacks[].StackName'
aws cloudformation describe-stacks --stack-name $STACK | jq -c '.Stacks[].StackStatus'
aws cloudformation describe-stacks --stack-name $STACK | jq -c '.Stacks[].Outputs'
aws cloudformation describe-stacks --stack-name CfgBucket --query "Stacks[0].Outputs[?OutputKey == 'BucketName'].OutputValue" --output text
aws cloudformation describe-stack-resources --stack-name $STACK | jq -c '.StackResources[].PhysicalResourceId'
aws cloudformation package \
    --template-file template.yaml \
    --s3-bucket ${ARTIFACT_BUCKET} \
    --output-template-file packaged.yaml
aws cloudformation deploy --s3-bucket $BUCKET --template-file packaged.yaml --capabilities CAPABILITY_NAMED_IAM --stack-name $STACK
aws cloudformation delete-stack --stack-name $STACK
aws cloudformation wait stack-delete-complete --stack-name $STACK
aws cloudformation continue-update-rollback --stack-name $STACK
aws cloudformation update-stack --stack-name mystack --use-previous-template
  --parameters ParameterKey=VPCID,UsePreviousValue=true ParameterKey=SubnetIDs,ParameterValue=SampleSubnetID1\\,UpdatedSampleSubnetID2
aws cloudformation detect-stack-drift --stack-name $STACK
aws cloudformation describe-stack-drift-detection-status --stack-drift-detection-id "ID-FROM-PREVIOUS-RESULT"

# aws.management.CloudWatch
aws logs describe-log-groups | jq -c '.logGroups[].logGroupName'
aws logs tag-log-group --log-group-name <value> --tags Key=str,Key=str
aws logs filter-log-events --log-stream-names $STREAM --log-group-name $GROUP --filter-pattern "$QUERY" | jq -r .events[].message
aws logs filter-log-events --log-group-name $GROUP --start-time $(date --date="1 day ago" +%s000) --filter-pattern "purchase_id" | jq -r '.events[] | [(.timestamp, .message)] | @csv'
aws logs get-log-events --log-group-name $GROUP --log-stream-name $STREAM
aws logs tail $GROUP --since '10m' --follow --format short
aws logs tail "/aws/lambda/$FUNCTION" --since '10m' --follow --format short
aws logs start-query --log-group-names $GROUP --start-time $(date --date="30 minutes ago" "+%s") --end-time $(date "+%s") --query-string 'fields @message, @logStream | filter @message '"$QUERY"' | sort @timestamp desc | limit 20' | jq -r .queryId
aws logs get-query-results --query-id $QID | jq -r '.results[][] | select(.field == "@message") | .value' | uniq
aws logs describe-log-groups | jq '.logGroups[] | select (has("retentionInDays") | not).logGroupName'
GROUP=$(aws logs describe-log-groups | jq -r '.logGroups[].logGroupName | select(test("Site-WS-EventFunction"))')
STREAM=$(aws logs describe-log-streams --log-group-name $GROUP --descending --max-items 1 | jq -r '.logStreams[0].logStreamName')
aws logs create-log-stream --log-group-name $GROUP --log-stream-name $(date "+%s")
aws logs delete-log-stream --log-group-name $GROUP --log-stream-name $STREAM

# aws.management.SSM (Systems Manager)
aws ssm list-documents --query 'DocumentIdentifiers[].Name'
aws ssm send-command --instance-ids $AWS_HOST --document-name $DOCUMENT --parameters "KeyName=string,string" --query 'Command.CommandId'
aws ssm get-command-invocation --instance-id $AWS_HOST --command-id $COMMAND

###### Cloudwatch Insights
fields @timestamp, @message
# Filtering all messages and keep only those that contains the word connect (case insensitive)
| filter @message like /(?i)(connect)/
# Create an ephemeral field named user based on the regex provided, in this case, either root or something like user18_prod
| parse @message /(?<@user>[.]*(root|user[0-9]{1,2}_[a-z]*)[.]*)/
# Create an ephemeral field named ip based on the regex provided (I know it's not the proper IP format, but it works for me)
| parse @message /(?<@ip>[.]*@([0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3})[.]*)/
# create an aggregate named counter from user and ip field
| stats count() AS counter by @user, @ip
# Sort first by the user field, then by the counter field
| sort by @user desc, @counter desc
| limit 50

parse @message '* *, * - - [*] "* * *" * * "*" "*"' as cloudfront, client, host, dateTimeString, httpVerb, url, protocol, statusCode, bytes, referer, userAgent
| fields @timestamp, @url, @statusCode
| filter statusCode like /5\d\d/
| count(*) as x by url
| sort x desc

fields @timestamp, @message
| filter @message like /cache.hit/
| fields strcontains(@message, "true") as @CacheHit,
         strcontains(@message, "false") as @CacheMiss
| stats sum(@CacheHit) as CacheHits, sum(@CacheMiss) as CacheMisses, sum(@CacheHit) / (sum(@CacheMiss) + sum(@CacheHit)) * 100 as HitPercentage by bin(30s)
| sort @timestamp desc

# aws.mobile.Amplify
npx create-react-app my-new-app
npm install aws-amplify @aws-amplify/ui-react
amplify init
amplify add api
amplify add function
amplify mock function myFunctionName --event "./event.json"
amplify add hosting
amplify push --allow-destructive-graphql-schema-updates
amplify publish --invalidateCloudFront
amplify delete

# aws.network.ELB (Elastic Load Balancing)

# aws.network.VPC (Virtual Private Cloud)

# aws.network.CF (CloudFront Delivery Network)

# aws.network.Route53
aws route53domains check-domain-availability --domain-name <value>
aws route53domains register-domain --domain-name <value>
ZONE=$(aws route53 list-hosted-zones-by-name --dns-name jbrinkmann.cloud --query 'HostedZones[0].Id' --output text)
aws route53 list-resource-record-sets --hosted-zone-id $ZONE --query 'ResourceRecordSets[?Type==`NS`].ResourceRecords[].Value'

# aws.network.APIGateway
aws apigateway test-invoke-method --rest-api-id $API_ID --resource-id $RES_ID --http-method GET --path-with-query-string '/pets/1'

aws securityhub get-findings \
    --filters '{"SeverityLabel":[{"Value":"CRITICAL", "Comparison":"EQUALS"}], "WorkflowStatus":[{"Value":"NEW", "Comparison":"EQUALS"}], "RecordState":[{"Value":"ACTIVE", "Comparison":"EQUALS"}]}' \
    --sort-criteria '{ "Field":"SeverityLabel", "SortOrder":"desc" }' \
    --max-items 1000
    
# aws.security.IAM (Identity and Access Management)
aws iam list-roles | jq -c '.Roles[].Arn'
aws iam create-user --user-name MyCdkUser
aws iam create-access-key --user-name MyCdkUser
aws iam delete-access-key --user-name MyCdkUser --access-key-id AKIAIOSFODNN7EXAMPLE
aws configure set aws_access_key_id us-west-2 --profile integ
aws configure set aws_secret_access_key us-west-2 --profile integ
aws iam list-policies --scope Local --only-attached --policy-usage-filter PermissionsPolicy --query Policies[]
aws iam get-policy-version --policy-arn <Arn> --version-id <DefaultVersionId>

# aws.security.STS (Security Token Service)
aws sts get-caller-identity --output json | jq '.Account' -r
aws sts get-caller-identity --query 'Arn' --output text
aws sts assume-role --role-arn $ROLE --role-session-name $USER
aws sts decode-authorization-message --encoded-message (encoded error message) --query DecodedMessage --output text | jq '.'

# aws.security.SecretsManager
aws secretsmanager create-secret --name $SECRET_NAME --secret-string $VALUE
aws secretsmanager list-secrets --query "SecretList[?contains(Name, 'ApiCredentials')].ARN" --output text
aws secretsmanager get-secret-value --secret-id $SECRET_NAME | jq -c '.SecretString | fromjson'
aws secretsmanager put-secret-value --secret-id $SECRET_NAME --secret-string "$VALUE"
aws secretsmanager delete-secret --secret-id $SECRET_NAME --force-delete-without-recovery

# aws.security.ACM
aws acm request-certificate \
  --domain-name $DOMAIN_NAME \
  --subject-alternative-names *.$DOMAIN_NAME \
  --validation-method DNS \
  --query CertificateArn \
  --output text
aws acm describe-certificate \
  --certificate-arn $SSL_CERT_ARN \
  --query Certificate.DomainValidationOptions
aws route53 list-hosted-zones-by-name \
  --dns-name $DOMAIN_NAME \
  --query HostedZones
  
# aws.security.Cognito
aws cognito-idp create-user-pool \
  --pool-name example-corp-prd-userpool
aws cognito-idp create-user-pool-domain \
  --domain example-corp-prd \
  --user-pool-id <yourUserPoolID>
aws cognito-idp update-user-pool-client --user-pool-id us-east-1_ABC \
  --client-id ABC2s2 \
  --allowed-o-auth-flows-user-pool-client \
  --allowed-o-auth-flows "code" "implicit" \
  --allowed-o-auth-scopes "openid" "profile" "email" \
  --callback-urls "[\"http://localhost:3000/\"]" \
  --supported-identity-providers "[\"MyIDP\"]"
aws cognito-idp list-user-pools --max-results 1 --query 'UserPools[0].Id' --output text
aws cognito-idp describe-user-pool --user-pool-id us-west-2_aaaaaaaaa
aws cognito-idp list-user-pool-clients --user-pool-id $UserPoolId \
  --query "UserPoolClients[?ClientName | contains(@, 'clientWeb')].ClientId"
aws cognito-idp describe-user-pool-client --user-pool-id $UserPoolId --client-id $ClientId
aws cognito-idp initiate-auth --region YOU_REGION --auth-flow USER_123456_AUTH --client-id YOUR_CLIENT_ID --auth-parameters jbrinkmann=YOUR_jbrinkmann@sonifi.com,123456=YOUR_123456
aws cognito-idp get-user --access-token $OAUTH_JWT_ACCESS_TOKEN

# aws.storage.S3 (Simple Storage Service)
aws s3api create-bucket --bucket $BUCKET
aws s3api list-buckets | jq -c '.Buckets[].Name'
aws s3api list-objects --bucket $BUCKET --prefix <XYZ> | jq -r '.Contents[].Key'
aws s3 cp --website-redirect "$URL" s3://$BUCKET/$OBJECT /tmp
aws s3 rb s3://BUCKET-NAME --force
aws s3api get-object --bucket $BUCKET --key $OBJECT /tmp/$OBJECT
aws s3 cp image.jpg s3://bucket_name/tests/image.jpg --acl public-read
